{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yFnrczEWDMm"
   },
   "source": [
    "# Natural language to SQL\n",
    "\n",
    "**Run in [Google Colab](https://colab.research.google.com/) For GPU.**\n",
    "\n",
    "This model have  Mistral as a base and it has been fine-tuned to excel in SQL code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kwUhBRwaLVZI"
   },
   "outputs": [],
   "source": [
    "#from google.colab import userdata\n",
    "#userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VNBGXh9V952",
    "outputId": "b89ebdab-f4e2-4659-89e1-ee5a63a8ede2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-uvbju7ua\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-uvbju7ua\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit fd9880da9123e595806a44e00536280d009fed99\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.1.0.dev0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.1.0.dev0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.1.0.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate==1.1.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.1.0.dev0) (2.1.1+cu121)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate==1.1.0.dev0)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate==1.1.0.dev0)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.1.0.dev0) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.0.dev0) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==1.1.0.dev0) (1.3.0)\n",
      "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-1.1.0.dev0-py3-none-any.whl size=331471 sha256=4c4606d1a6b57de65edbc570994fd4986bceacc6c19fad455ca65b0e314290d0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ykr0r65s/wheels/23/11/1b/0ca34d88046a6046afe81294675e7c45458915c052f48a8450\n",
      "Successfully built accelerate\n",
      "Installing collected packages: safetensors, huggingface-hub, accelerate\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.0\n",
      "    Uninstalling safetensors-0.4.0:\n",
      "      Successfully uninstalled safetensors-0.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.24.1\n",
      "    Uninstalling accelerate-0.24.1:\n",
      "      Successfully uninstalled accelerate-0.24.1\n",
      "Successfully installed accelerate-1.1.0.dev0 huggingface-hub-0.25.2 safetensors-0.4.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-1mo_qle4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-1mo_qle4\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 69b5ccb8878b58372ea326d17d9490d67ccf23a7\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.46.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n",
      "  Downloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.46.0.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.46.0.dev0) (2020.6.20)\n",
      "Downloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9962467 sha256=993bd990be319f165c0de11b49f16895f7626fbe5c7e2db6c27c0ac1cf268ba9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-17y5ouwj/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.1\n",
      "    Uninstalling tokenizers-0.15.1:\n",
      "      Successfully uninstalled tokenizers-0.15.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "Successfully installed tokenizers-0.20.0 transformers-4.46.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.41.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Install the lastest versions of peft & transformers library recommended\n",
    "#if you want to work with the most recent models\n",
    "!pip install -q git+https://github.com/huggingface/peft.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U1mZ27vbXBCE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rotsX3i-XLJS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"defog/sqlcoder-7b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fHZsPTa5yun"
   },
   "source": [
    "We need to create the Quantization configuration to load the Model.\n",
    "\n",
    "It is a large model and I want it to fit in a 16GB GPU, I'm going to use a 4 bits quantization.\n",
    "\n",
    "If you want to learn more about quantization, refer to this article: [QLoRA: Training a Large Language Model on a 16GB GPU.](https://medium.com/towards-artificial-intelligence/qlora-training-a-large-language-model-on-a-16gb-gpu-00ea965667c1)\n",
    "\n",
    "You can try to use this model in a 8 bit quantizations and check in you see any improvements in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oio2Fm7GXa6K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "915oTn7T6fvW"
   },
   "source": [
    "To load the model I pass to the AutoModelForCasualLM teh quantization configurations, and HuggingFace take care of all the hard work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "d98d5330709041ceb8ec0399efb462eb",
      "6753e1aaa26d4f08bfcd74175c234048",
      "c31363aec2824326a0e7bb7b79d349a9",
      "fa6593f1e0694ab0ab359e553822c8e1",
      "97d6971929004c34903434796d43ece9",
      "e99c618afa5243dbb3a490019fe6b341",
      "7a4b434805694ae6b4fa73525e0c8414",
      "f3852216b35f4a1f835cb256b84059d6",
      "43fc08e86e874773b4a7e3787e89e612",
      "965082fc66fa44c2b7b246876fe7f618",
      "7c0288617bae4144ba7976c14ae5deff",
      "93e38719082a4138a56a9810267e271f",
      "ddda691d9c1a4b8d883e4f60e872bb45",
      "1e0fffcc51024bcebf269df2340e28ff",
      "2a87740b4c0c4d29a138017e536ffca5",
      "5c8aec484078410eb78f754d91ee7441",
      "322ce8cdd35f40a5a4f2fa0f446c69dc",
      "65524f45793a4ba296098fccacdd5147",
      "13d405ffd51e4bc39a7b2d2b1f10269b",
      "698b436d260543ccba365be37836d830",
      "89d49f3f222141c480d6d7c7331e9486",
      "dc4a65b3471949b68c6c777f3f161cb9",
      "b7609e7dcb0c401b8788a46e4ebb2c16",
      "805f2b8ad48c40bc82825da23258e5e8",
      "865819a656854889ae9566b7d30e91db",
      "a83ae7ec71d54ca0a427f195ecda44bd",
      "cd977777435c4eec9b28a08d4376b34f",
      "0063a429bb3441c0aced2a29f189aefb",
      "09af33499fea408ab9896a1d57241486",
      "2c84206efbf04209baba23974da3ee01",
      "9bf84f12380e454dbff0e1253d506fc2",
      "730e26ac245a46249895dbb4d238c979",
      "92f86d54570f45d4b8ea106437f06b68",
      "34e21fd56d83456e9b9371596762febd",
      "c0d93ec10305440bbddc9ea595d9789e",
      "19668b7a761342718e15bdb6463114f5",
      "8fa29a67162444428c20ff7b5595cc44",
      "2bfc6b45fc3744549283f9b576c73c25",
      "0e91aa007703424ab33be074167c233d",
      "a186703f191a461b8724f24228814a56",
      "cbbe675b34484c11bcec6f5fbc8d2a19",
      "5ef6b982050a4b87a4e4276459e81be1",
      "c5346742693b45d9bd5f559c2a7ba216",
      "06cbdddbddb74d6c8e78f1b54b69c32e",
      "a29e400e69be41389f37be8785b21046",
      "75c8f53b343649fa9641434d63430725",
      "54e5d2a340b847bc84a2ee0033354c20",
      "fb055c6c3bbf41209575939de66692cf",
      "31ec3fd93595473183ec3a339a330ba3",
      "7bdddc93dfd345adb4c679da9a657c68",
      "4803c23d32d44c1db951f95132fdd808",
      "a4495ac4084943a5bb2a0d4e81d66305",
      "16650b562a314c2bbf8a959e134952a2",
      "eb0c197d18714e7fb998c88310983213",
      "832951cebac64a60a617cc1292641305",
      "869c6ec46d484cedb76e9855752a710e",
      "05461510d78e404aad02d805c316251a",
      "a1c12e8070b24888a448f345f9a38817",
      "31466390f2b344d79e9831c1f34992d8",
      "d0645e58ebbd493888ba4c3f54b82bed",
      "5a30606e6c9845ce9ab1964e48b1320b",
      "4c50cb0268fa48b884833e2d3d320cf0",
      "4b16e1912e6145c7b8fb7d745f60e143",
      "43bdf631b87b4f548121738dbba12e72",
      "c834ad62b50e4ca98d1595aa168eabbf",
      "0f78893e0e1f4430b06d86d0ef67667f"
     ]
    },
    "id": "Q8-VpiCBXcst",
    "outputId": "6bee9a5a-ac75-447c-a4df-ad6df4cff197",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ce7703070549089244097917810bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56981ef49564fd5bbd4d7b9d8813a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2f2520850b4255b1cbb05f704ed431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db10bfedd56241768090e240372d16d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b2febd04334686a511c8e0d41d2add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d41fdfc88c47bdac40c54c0436fd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8020fe40b64489f9fd7bd421ad39741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                    quantization_config=bnb_config,\n",
    "                    device_map='auto',\n",
    "                    use_cache = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E2Oz6Sm8X5Qo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df400aadab084d35b09594900978123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82278efb73274a0c877bca739a4adcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ecf9a3f80b4b3b89b77861d343cc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384898d3ff7a45518b6eda88490a629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV-Qk6327Z30"
   },
   "source": [
    "This function wraps the call to *model.generate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l4vEDNRGtvdn"
   },
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens=400):\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=eos_token_id,\n",
    "        pad_token_id=eos_token_id,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        num_beams=5\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y88PVExjKCvQ"
   },
   "source": [
    "# Prompt without Shots.\n",
    "In this first PROMPT we are going to give Instructions to the model and pass the structure of the Database.\n",
    "\n",
    "The instructions are significantly different from those we are passing to GPT-3.5-Turbo. This model is really well fine-tuned, but it is smaller than GPT-3.5.\n",
    "\n",
    "We need to be more clear with the instructions, as it does not have the same capacity to understand our orders as GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U8K4XWDQJH_p"
   },
   "outputs": [],
   "source": [
    "sp_nl2sql = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 3+ TABLES HERE\n",
    "\n",
    "    ### Response\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIgEZpmSlG0I",
    "outputId": "055fb51f-e77b-4e80-ce55-cdff797b5d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    CREATE 3+ TABLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Create 5 tables`:\n",
      "    ```sql3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sp_nl2sql = sp_nl2sql.format(question=\"Create 5 tables\")\n",
    "print(sp_nl2sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Mp3TDRQtltX9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 09:29:30.684278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 09:29:30.684401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 09:29:30.685796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 09:29:30.693115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 09:29:31.547352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "input_sentences = tokenizer(sp_nl2sql, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hWouSh-7rpCk"
   },
   "outputs": [],
   "source": [
    "#Empty the cache in orde to do more calls without problems.\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0V5XuDp0sCi",
    "outputId": "63276a47-274b-4c77-b7e8-155e7a09862f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) AS total_reviews FROM review;\n"
     ]
    }
   ],
   "source": [
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKrjztcK-zDm"
   },
   "source": [
    "The SQL Order is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0hogn4fKP1f"
   },
   "source": [
    "#Prompt with shots OpenAI Style.\n",
    "In this second prompt we are going to add some Shots with samples to see if our SQL style affects the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qNPXi3twuN7-"
   },
   "outputs": [],
   "source": [
    "sp_nl2sql2 = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use the samples SQL In the ### Samples section to clearn more about teh Databases structure\n",
    "\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 4+ TABLES HERE\n",
    "\n",
    "    ### Response\n",
    "    YOUR QERIES AND SAMPLE RESPONSES HERE\n",
    "\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vy338SDLr5u",
    "outputId": "ec85a34f-de0c-40d2-bc4f-cb71e2b4df9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to clearn more about teh Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "   YOUR TABLES HERE\n",
      "\n",
      "    ### Response\n",
      "    YOUR QERIES AND SAMPLE RESPONSES HERE\n",
      "\n",
      "    `Return The name of the best paid employee`:\n",
      "    ```sql3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sp_nl2sql2 = sp_nl2sql2.format(question=\"Return The name of the best paid employee\")\n",
    "(print(sp_nl2sql2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Cvk9hJfhLwQJ"
   },
   "outputs": [],
   "source": [
    "input_sentences = tokenizer(sp_nl2sql2, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQOyi8ZOL1mr",
    "outputId": "f30b2689-72f1-432a-f957-b47ab2e9732c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT employees.first_name, employees.last_name, MAX(employees.salary) AS max_salary FROM employees GROUP BY employees.first_name, employees.last_name ORDER BY max_salary DESC NULLS LAST LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buwuhLBw_MAV"
   },
   "source": [
    "The Order is really different from the one obtained with the first prompt.\n",
    "\n",
    "The first difference is the format. But The SQL is realy more simple, at least it is my sensation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6S6gI_fNtFk"
   },
   "source": [
    "#Prompt with Shots in Sample Style.\n",
    "\n",
    "In this prompt, we will place the examples in a separate section, and in the instructions, we will instruct the model to pay attention to them in order to generate the SQL commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oHSF1l3xNscJ"
   },
   "outputs": [],
   "source": [
    "sp_nl2sql3b = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
    "\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 4+ TABLES HERE\n",
    "    \n",
    "    ### Samples\n",
    "    \n",
    "    YOUR SAMPLES HERE\n",
    "\n",
    "    ### Response\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCfbmvDyOS-u",
    "outputId": "dd192eb6-7d08-4456-d1cb-3dd44e869631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    YOUR TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Return The name of the best paid employee`:\n",
      "    ```sql3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sp_nl2sql3 = sp_nl2sql3b.format(question=\"Return The name of the best paid employee\")\n",
    "print (sp_nl2sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VxsIf4KBOWCk"
   },
   "outputs": [],
   "source": [
    "input_sentences = tokenizer(sp_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sE5_a8jOaJ7",
    "outputId": "e0e63a3c-e4cc-4aa5-ecb6-94b69587b2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT employees.first_name, employees.last_name, MAX(employees.salary) AS max_salary FROM employees GROUP BY employees.first_name, employees.last_name ORDER BY max_salary DESC NULLS LAST LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5OgzBzKNHzn"
   },
   "source": [
    "#Now the question in spanish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQuJNMjNFU6a",
    "outputId": "4e403588-5a4e-4a5e-ee37-710381c1e987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    YOUR TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Volver El nombre del empleado mejor pagado`:\n",
      "    ```sql3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sp_nl2sql3 = sp_nl2sql3b.format(question=\"Volver El nombre del empleado mejor pagado\")\n",
    "print (sp_nl2sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rBGokR4RFfrK"
   },
   "outputs": [],
   "source": [
    "input_sentences = tokenizer(sp_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEoQgcoUHXXJ",
    "outputId": "75922491-331c-4b12-8798-e7f328101236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instructions:\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    YOUR TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have;\n"
     ]
    }
   ],
   "source": [
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHZn6nGCH2RS"
   },
   "source": [
    "The generated SQL command is the same regardless of where we have placed the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrHGZjraCYSR"
   },
   "source": [
    "#Conclusions.\n",
    "\n",
    "Let's see the three SQL's together.\n",
    "\n",
    "* SELECT employees.name, MAX(salary.salary) AS max_salary FROM employees JOIN salary ON employees.ID_Usr = salary.ID_Usr GROUP BY employees.name ORDER BY max_salary DESC NULLS LAST LIMIT 1;\n",
    "\n",
    "* SELECT e.name\n",
    "    FROM employees e\n",
    "    JOIN salary s ON e.ID_Usr = s.ID_usr\n",
    "    WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
    "\n",
    "* SELECT e.name\n",
    "    FROM employees e\n",
    "    JOIN salary s ON e.ID_Usr = s.ID_usr\n",
    "    WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
    "\n",
    "* Spanish Question: SELECT e.name\n",
    "     FROM employees e\n",
    "     JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
    "     WHERE s.salary = (SELECT MAX(salary) FROM salary)\n",
    "     GROUP BY e.name\n",
    "     ORDER BY COUNT(studies.ID_study) DESC\n",
    "     LIMIT 1;\n",
    "\n",
    "\n",
    "**The model has demonstrated that it is highly efficient in crafting SQL.** Additionally, it pays a lot of attention, perhaps too much, to the examples we provide. Clearly, these examples should be crafted by one of the best SQL programmers we have access to, though their use may not be essential.\n",
    "\n",
    "On the other hand, although the model is clearly very proficient in SQL generation, during the creation of the notebook, I have encountered several issues because the commands need to be extremely clear. It doesn't handle typos well (which should not exist).\n",
    "\n",
    "It appears to have some issues when it receives commands in Spanish. I assume this problem would be present in any language other than English. Therefore, since it's a tool that could be used by non-technical personnel, this should be considered in environments where English is not the primary language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P45ukTZyHdFE"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to have a german request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_nl2sql3b = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
    "\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 4+ TABLES HERE\n",
    "    \n",
    "    ### Samples\n",
    "    \n",
    "    YOUR SAMPLES HERE\n",
    "\n",
    "    ### Response\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    CREATE 4+ TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Finde den Namen des best bezahltesten Arbeitnehmers`:\n",
      "    ```sql3\n",
      "    \n",
      "### Instructions:\n",
      "Your task is function a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use;\n"
     ]
    }
   ],
   "source": [
    "de_nl2sql3 = de_nl2sql3b.format(question=\"Finde den Namen des best bezahltesten Arbeitnehmers\")\n",
    "print (de_nl2sql3)\n",
    "\n",
    "input_sentences = tokenizer(de_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to look for the least paid employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "empllow_nl2sql3b = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
    "\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 4+ TABLES HERE\n",
    "    \n",
    "    ### Samples\n",
    "    \n",
    "    YOUR SAMPLES HERE\n",
    "\n",
    "    ### Response\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    CREATE 4+ TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Return The name of the lead paid employee`:\n",
      "    ```sql3\n",
      "    \n",
      "### Instructions:\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    CREATE 4+ TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have returned to answer the question\n",
      "    `return The name of the lead paid employee`:;\n"
     ]
    }
   ],
   "source": [
    "empllow_nl2 = empllow_nl2sql3b.format(question=\"Return The name of the lead paid employee\")\n",
    "print (empllow_nl2)\n",
    "\n",
    "input_sentences = tokenizer(empllow_nl2, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different request: Look for heavyweight boxers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxing_nl2sql3b = \"\"\"\n",
    "    ### Instructions:\n",
    "Your task is convert a question into a SQL query, given a SQL database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
    "\n",
    "\n",
    "    ### Input\n",
    "    Generate a SQL query that answers the question below.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "    CREATE 4+ TABLES HERE\n",
    "    \n",
    "    ### Samples\n",
    "    \n",
    "    YOUR SAMPLES HERE\n",
    "\n",
    "    ### Response\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
    "    `{question}`:\n",
    "    ```sql3\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Instructions:\n",
      "Your task is convert a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use the samples SQL In the ### Samples section to learn more about the Databases structure\n",
      "\n",
      "\n",
      "    ### Input\n",
      "    Generate a SQL query that answers the question below.\n",
      "    This query will run on a database whose schema is represented in this string:\n",
      "\n",
      "    CREATE 4+ TABLES HERE\n",
      "    \n",
      "    ### Samples\n",
      "    \n",
      "    YOUR SAMPLES HERE\n",
      "\n",
      "    ### Response\n",
      "    Based on your instructions, here is the SQL query I have generated to answer the question\n",
      "    `Please return the top 5 of heavywight boxyers at the WBA`:\n",
      "    ```sql3\n",
      "    \n",
      "### Instructions:\n",
      "Your task is function a question into a SQL query, given a SQL database schema.\n",
      "Adhere to these rules:\n",
      "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
      "- **Use;\n"
     ]
    }
   ],
   "source": [
    "boxing_nl2sql3 = boxing_nl2sql3b.format(question=\"Please return the top 5 of heavywight boxyers at the WBA\")\n",
    "print (boxing_nl2sql3)\n",
    "\n",
    "input_sentences = tokenizer(boxing_nl2sql3, return_tensors=\"pt\").to('cuda')\n",
    "response = get_outputs(foundation_model, input_sentences, max_new_tokens=400)\n",
    "SQL = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(SQL[0].split(\"```sql3\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0063a429bb3441c0aced2a29f189aefb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05461510d78e404aad02d805c316251a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a30606e6c9845ce9ab1964e48b1320b",
      "placeholder": "​",
      "style": "IPY_MODEL_4c50cb0268fa48b884833e2d3d320cf0",
      "value": "generation_config.json: 100%"
     }
    },
    "06cbdddbddb74d6c8e78f1b54b69c32e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09af33499fea408ab9896a1d57241486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e91aa007703424ab33be074167c233d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f78893e0e1f4430b06d86d0ef67667f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13d405ffd51e4bc39a7b2d2b1f10269b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16650b562a314c2bbf8a959e134952a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19668b7a761342718e15bdb6463114f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbbe675b34484c11bcec6f5fbc8d2a19",
      "max": 4540536863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ef6b982050a4b87a4e4276459e81be1",
      "value": 4540536863
     }
    },
    "1e0fffcc51024bcebf269df2340e28ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13d405ffd51e4bc39a7b2d2b1f10269b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_698b436d260543ccba365be37836d830",
      "value": 2
     }
    },
    "2a87740b4c0c4d29a138017e536ffca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89d49f3f222141c480d6d7c7331e9486",
      "placeholder": "​",
      "style": "IPY_MODEL_dc4a65b3471949b68c6c777f3f161cb9",
      "value": " 2/2 [01:35&lt;00:00, 44.43s/it]"
     }
    },
    "2bfc6b45fc3744549283f9b576c73c25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c84206efbf04209baba23974da3ee01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31466390f2b344d79e9831c1f34992d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c834ad62b50e4ca98d1595aa168eabbf",
      "placeholder": "​",
      "style": "IPY_MODEL_0f78893e0e1f4430b06d86d0ef67667f",
      "value": " 116/116 [00:00&lt;00:00, 7.37kB/s]"
     }
    },
    "31ec3fd93595473183ec3a339a330ba3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "322ce8cdd35f40a5a4f2fa0f446c69dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e21fd56d83456e9b9371596762febd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0d93ec10305440bbddc9ea595d9789e",
       "IPY_MODEL_19668b7a761342718e15bdb6463114f5",
       "IPY_MODEL_8fa29a67162444428c20ff7b5595cc44"
      ],
      "layout": "IPY_MODEL_2bfc6b45fc3744549283f9b576c73c25"
     }
    },
    "43bdf631b87b4f548121738dbba12e72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43fc08e86e874773b4a7e3787e89e612": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4803c23d32d44c1db951f95132fdd808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b16e1912e6145c7b8fb7d745f60e143": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c50cb0268fa48b884833e2d3d320cf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54e5d2a340b847bc84a2ee0033354c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4495ac4084943a5bb2a0d4e81d66305",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16650b562a314c2bbf8a959e134952a2",
      "value": 2
     }
    },
    "5a30606e6c9845ce9ab1964e48b1320b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c8aec484078410eb78f754d91ee7441": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ef6b982050a4b87a4e4276459e81be1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65524f45793a4ba296098fccacdd5147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6753e1aaa26d4f08bfcd74175c234048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e99c618afa5243dbb3a490019fe6b341",
      "placeholder": "​",
      "style": "IPY_MODEL_7a4b434805694ae6b4fa73525e0c8414",
      "value": "pytorch_model.bin.index.json: 100%"
     }
    },
    "698b436d260543ccba365be37836d830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "730e26ac245a46249895dbb4d238c979": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c8f53b343649fa9641434d63430725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bdddc93dfd345adb4c679da9a657c68",
      "placeholder": "​",
      "style": "IPY_MODEL_4803c23d32d44c1db951f95132fdd808",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7a4b434805694ae6b4fa73525e0c8414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bdddc93dfd345adb4c679da9a657c68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c0288617bae4144ba7976c14ae5deff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "805f2b8ad48c40bc82825da23258e5e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0063a429bb3441c0aced2a29f189aefb",
      "placeholder": "​",
      "style": "IPY_MODEL_09af33499fea408ab9896a1d57241486",
      "value": "pytorch_model-00001-of-00002.bin: 100%"
     }
    },
    "832951cebac64a60a617cc1292641305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "865819a656854889ae9566b7d30e91db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c84206efbf04209baba23974da3ee01",
      "max": 9943030860,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9bf84f12380e454dbff0e1253d506fc2",
      "value": 9943030860
     }
    },
    "869c6ec46d484cedb76e9855752a710e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05461510d78e404aad02d805c316251a",
       "IPY_MODEL_a1c12e8070b24888a448f345f9a38817",
       "IPY_MODEL_31466390f2b344d79e9831c1f34992d8"
      ],
      "layout": "IPY_MODEL_d0645e58ebbd493888ba4c3f54b82bed"
     }
    },
    "89d49f3f222141c480d6d7c7331e9486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fa29a67162444428c20ff7b5595cc44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5346742693b45d9bd5f559c2a7ba216",
      "placeholder": "​",
      "style": "IPY_MODEL_06cbdddbddb74d6c8e78f1b54b69c32e",
      "value": " 4.54G/4.54G [00:27&lt;00:00, 119MB/s]"
     }
    },
    "92f86d54570f45d4b8ea106437f06b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93e38719082a4138a56a9810267e271f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddda691d9c1a4b8d883e4f60e872bb45",
       "IPY_MODEL_1e0fffcc51024bcebf269df2340e28ff",
       "IPY_MODEL_2a87740b4c0c4d29a138017e536ffca5"
      ],
      "layout": "IPY_MODEL_5c8aec484078410eb78f754d91ee7441"
     }
    },
    "965082fc66fa44c2b7b246876fe7f618": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97d6971929004c34903434796d43ece9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bf84f12380e454dbff0e1253d506fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a186703f191a461b8724f24228814a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1c12e8070b24888a448f345f9a38817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b16e1912e6145c7b8fb7d745f60e143",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43bdf631b87b4f548121738dbba12e72",
      "value": 116
     }
    },
    "a29e400e69be41389f37be8785b21046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75c8f53b343649fa9641434d63430725",
       "IPY_MODEL_54e5d2a340b847bc84a2ee0033354c20",
       "IPY_MODEL_fb055c6c3bbf41209575939de66692cf"
      ],
      "layout": "IPY_MODEL_31ec3fd93595473183ec3a339a330ba3"
     }
    },
    "a4495ac4084943a5bb2a0d4e81d66305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a83ae7ec71d54ca0a427f195ecda44bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_730e26ac245a46249895dbb4d238c979",
      "placeholder": "​",
      "style": "IPY_MODEL_92f86d54570f45d4b8ea106437f06b68",
      "value": " 9.94G/9.94G [01:07&lt;00:00, 249MB/s]"
     }
    },
    "b7609e7dcb0c401b8788a46e4ebb2c16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_805f2b8ad48c40bc82825da23258e5e8",
       "IPY_MODEL_865819a656854889ae9566b7d30e91db",
       "IPY_MODEL_a83ae7ec71d54ca0a427f195ecda44bd"
      ],
      "layout": "IPY_MODEL_cd977777435c4eec9b28a08d4376b34f"
     }
    },
    "c0d93ec10305440bbddc9ea595d9789e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e91aa007703424ab33be074167c233d",
      "placeholder": "​",
      "style": "IPY_MODEL_a186703f191a461b8724f24228814a56",
      "value": "pytorch_model-00002-of-00002.bin: 100%"
     }
    },
    "c31363aec2824326a0e7bb7b79d349a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3852216b35f4a1f835cb256b84059d6",
      "max": 23950,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43fc08e86e874773b4a7e3787e89e612",
      "value": 23950
     }
    },
    "c5346742693b45d9bd5f559c2a7ba216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c834ad62b50e4ca98d1595aa168eabbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbbe675b34484c11bcec6f5fbc8d2a19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd977777435c4eec9b28a08d4376b34f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0645e58ebbd493888ba4c3f54b82bed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d98d5330709041ceb8ec0399efb462eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6753e1aaa26d4f08bfcd74175c234048",
       "IPY_MODEL_c31363aec2824326a0e7bb7b79d349a9",
       "IPY_MODEL_fa6593f1e0694ab0ab359e553822c8e1"
      ],
      "layout": "IPY_MODEL_97d6971929004c34903434796d43ece9"
     }
    },
    "dc4a65b3471949b68c6c777f3f161cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddda691d9c1a4b8d883e4f60e872bb45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_322ce8cdd35f40a5a4f2fa0f446c69dc",
      "placeholder": "​",
      "style": "IPY_MODEL_65524f45793a4ba296098fccacdd5147",
      "value": "Downloading shards: 100%"
     }
    },
    "e99c618afa5243dbb3a490019fe6b341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb0c197d18714e7fb998c88310983213": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3852216b35f4a1f835cb256b84059d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa6593f1e0694ab0ab359e553822c8e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_965082fc66fa44c2b7b246876fe7f618",
      "placeholder": "​",
      "style": "IPY_MODEL_7c0288617bae4144ba7976c14ae5deff",
      "value": " 23.9k/23.9k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "fb055c6c3bbf41209575939de66692cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb0c197d18714e7fb998c88310983213",
      "placeholder": "​",
      "style": "IPY_MODEL_832951cebac64a60a617cc1292641305",
      "value": " 2/2 [01:08&lt;00:00, 31.76s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
